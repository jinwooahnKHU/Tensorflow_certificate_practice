{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f38cf05",
   "metadata": {},
   "source": [
    "# Tensorflow Certificate C3W4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36c74597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T04:16:30.815511Z",
     "start_time": "2021-11-18T04:16:28.650553Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.utils as ku\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9b5cee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T04:16:56.957744Z",
     "start_time": "2021-11-18T04:16:53.628677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=108jAePKK4R3BVYBbYJZ32JWUwxeMg20K\n",
      "To: /Users/jinwooahn/Documents/dev_folder/2021_2nd_semester/tensorflow_certificate/C3/W4/sonnets.txt\n",
      "100%|███████████████████████████████████████| 93.6k/93.6k [00:00<00:00, 385kB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "#download text\n",
    "!gdown --id 108jAePKK4R3BVYBbYJZ32JWUwxeMg20K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92b56b5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T05:19:56.286001Z",
     "start_time": "2021-11-18T05:19:56.180663Z"
    }
   },
   "outputs": [],
   "source": [
    "data = open('./sonnets.txt').read()\n",
    "corpus = data.lower().split('\\n')\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1 #이거 왜 1 더하지? (oov때문인가)\n",
    "\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "#     print(token_list)\n",
    "    #ngram 묶기\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "#pad sequences\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "predictors, label = input_sequences[:,:-1], input_sequences[:,-1]\n",
    "\n",
    "label = ku.to_categorical(label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5f51992",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T05:19:59.571018Z",
     "start_time": "2021-11-18T05:19:59.566358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15462, 11)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "991573d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T05:19:59.923436Z",
     "start_time": "2021-11-18T05:19:59.919749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15462 15462\n"
     ]
    }
   ],
   "source": [
    "print(len(predictors), len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7465d11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T05:24:30.806817Z",
     "start_time": "2021-11-18T05:24:30.565102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 10, 100)           321100    \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 10, 300)           301200    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1605)              162105    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3211)              5156866   \n",
      "=================================================================\n",
      "Total params: 6,101,671\n",
      "Trainable params: 6,101,671\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length = max_sequence_len -1 ))\n",
    "model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "#dense layer including L2 regularizer\n",
    "model.add(Dense(total_words / 2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5180fc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T05:53:25.021593Z",
     "start_time": "2021-11-18T05:24:33.910892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 14:24:34.905984: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-18 14:24:35.070333: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-18 14:24:35.083363: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-18 14:24:35.148125: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-18 14:24:35.207825: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-18 14:24:35.285125: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-18 14:24:35.300214: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484/484 [==============================] - 17s 32ms/step - loss: 6.9536 - accuracy: 0.0188\n",
      "Epoch 2/100\n",
      "484/484 [==============================] - 15s 31ms/step - loss: 6.5923 - accuracy: 0.0202\n",
      "Epoch 3/100\n",
      "484/484 [==============================] - 15s 31ms/step - loss: 6.5669 - accuracy: 0.0223\n",
      "Epoch 4/100\n",
      "484/484 [==============================] - 15s 31ms/step - loss: 6.5645 - accuracy: 0.0210\n",
      "Epoch 5/100\n",
      "484/484 [==============================] - 15s 31ms/step - loss: 6.5602 - accuracy: 0.0220\n",
      "Epoch 6/100\n",
      "484/484 [==============================] - 15s 31ms/step - loss: 6.5594 - accuracy: 0.0237\n",
      "Epoch 7/100\n",
      "484/484 [==============================] - 15s 31ms/step - loss: 6.5581 - accuracy: 0.0212\n",
      "Epoch 8/100\n",
      "484/484 [==============================] - 15s 31ms/step - loss: 6.5559 - accuracy: 0.0227\n",
      "Epoch 9/100\n",
      "484/484 [==============================] - 15s 31ms/step - loss: 6.5552 - accuracy: 0.0239\n",
      "Epoch 10/100\n",
      "484/484 [==============================] - 15s 31ms/step - loss: 6.5540 - accuracy: 0.0220\n",
      "Epoch 11/100\n",
      "484/484 [==============================] - 15s 31ms/step - loss: 6.5537 - accuracy: 0.0224\n",
      "Epoch 12/100\n",
      "484/484 [==============================] - 15s 31ms/step - loss: 6.5531 - accuracy: 0.0208\n",
      "Epoch 13/100\n",
      "484/484 [==============================] - 15s 31ms/step - loss: 6.5510 - accuracy: 0.0206\n",
      "Epoch 14/100\n",
      "484/484 [==============================] - 15s 32ms/step - loss: 6.5501 - accuracy: 0.0225\n",
      "Epoch 15/100\n",
      "484/484 [==============================] - 15s 31ms/step - loss: 6.5497 - accuracy: 0.0214\n",
      "Epoch 16/100\n",
      "484/484 [==============================] - 15s 32ms/step - loss: 6.5485 - accuracy: 0.0222\n",
      "Epoch 17/100\n",
      "484/484 [==============================] - 15s 32ms/step - loss: 6.5479 - accuracy: 0.0221\n",
      "Epoch 18/100\n",
      "484/484 [==============================] - 15s 32ms/step - loss: 6.5464 - accuracy: 0.0221\n",
      "Epoch 19/100\n",
      "484/484 [==============================] - 15s 32ms/step - loss: 6.5468 - accuracy: 0.0231\n",
      "Epoch 20/100\n",
      "484/484 [==============================] - 15s 32ms/step - loss: 6.5450 - accuracy: 0.0230\n",
      "Epoch 21/100\n",
      "484/484 [==============================] - 16s 32ms/step - loss: 6.5438 - accuracy: 0.0222\n",
      "Epoch 22/100\n",
      "484/484 [==============================] - 16s 32ms/step - loss: 6.5447 - accuracy: 0.0223\n",
      "Epoch 23/100\n",
      "484/484 [==============================] - 16s 32ms/step - loss: 6.5439 - accuracy: 0.0222\n",
      "Epoch 24/100\n",
      "484/484 [==============================] - 16s 32ms/step - loss: 6.5429 - accuracy: 0.0239\n",
      "Epoch 25/100\n",
      "484/484 [==============================] - 16s 33ms/step - loss: 6.5424 - accuracy: 0.0220\n",
      "Epoch 26/100\n",
      "484/484 [==============================] - 17s 34ms/step - loss: 6.5426 - accuracy: 0.0233\n",
      "Epoch 27/100\n",
      "484/484 [==============================] - 17s 35ms/step - loss: 6.5414 - accuracy: 0.0223\n",
      "Epoch 28/100\n",
      "484/484 [==============================] - 17s 36ms/step - loss: 6.5409 - accuracy: 0.0229\n",
      "Epoch 29/100\n",
      "484/484 [==============================] - 18s 37ms/step - loss: 6.5404 - accuracy: 0.0220\n",
      "Epoch 30/100\n",
      "484/484 [==============================] - 18s 38ms/step - loss: 6.5398 - accuracy: 0.0231\n",
      "Epoch 31/100\n",
      "484/484 [==============================] - 18s 38ms/step - loss: 6.5397 - accuracy: 0.0220\n",
      "Epoch 32/100\n",
      "484/484 [==============================] - 19s 39ms/step - loss: 6.5413 - accuracy: 0.0227\n",
      "Epoch 33/100\n",
      "484/484 [==============================] - 19s 39ms/step - loss: 6.5389 - accuracy: 0.0230\n",
      "Epoch 34/100\n",
      "484/484 [==============================] - 19s 39ms/step - loss: 6.5485 - accuracy: 0.0218\n",
      "Epoch 35/100\n",
      "484/484 [==============================] - 19s 40ms/step - loss: 6.5360 - accuracy: 0.0234\n",
      "Epoch 36/100\n",
      "484/484 [==============================] - 19s 40ms/step - loss: 6.5316 - accuracy: 0.0236\n",
      "Epoch 37/100\n",
      "484/484 [==============================] - 19s 40ms/step - loss: 6.5287 - accuracy: 0.0225\n",
      "Epoch 38/100\n",
      "484/484 [==============================] - 19s 40ms/step - loss: 6.5241 - accuracy: 0.0250\n",
      "Epoch 39/100\n",
      "484/484 [==============================] - 20s 40ms/step - loss: 6.5173 - accuracy: 0.0243\n",
      "Epoch 40/100\n",
      "484/484 [==============================] - 20s 41ms/step - loss: 6.5033 - accuracy: 0.0238\n",
      "Epoch 41/100\n",
      "484/484 [==============================] - 20s 41ms/step - loss: 6.4873 - accuracy: 0.0263\n",
      "Epoch 42/100\n",
      "484/484 [==============================] - 20s 41ms/step - loss: 6.4636 - accuracy: 0.0274\n",
      "Epoch 43/100\n",
      "484/484 [==============================] - 20s 42ms/step - loss: 6.4485 - accuracy: 0.0303\n",
      "Epoch 44/100\n",
      "484/484 [==============================] - 20s 42ms/step - loss: 6.4236 - accuracy: 0.0307\n",
      "Epoch 45/100\n",
      "484/484 [==============================] - 21s 42ms/step - loss: 6.4012 - accuracy: 0.0316\n",
      "Epoch 46/100\n",
      "484/484 [==============================] - 21s 43ms/step - loss: 6.3797 - accuracy: 0.0324\n",
      "Epoch 47/100\n",
      "484/484 [==============================] - 21s 43ms/step - loss: 6.3502 - accuracy: 0.0314\n",
      "Epoch 48/100\n",
      "484/484 [==============================] - 21s 44ms/step - loss: 6.3235 - accuracy: 0.0325\n",
      "Epoch 49/100\n",
      "484/484 [==============================] - 21s 44ms/step - loss: 6.2992 - accuracy: 0.0329\n",
      "Epoch 50/100\n",
      "484/484 [==============================] - 21s 44ms/step - loss: 6.2776 - accuracy: 0.0304\n",
      "Epoch 51/100\n",
      "484/484 [==============================] - 21s 44ms/step - loss: 6.2517 - accuracy: 0.0311\n",
      "Epoch 52/100\n",
      "484/484 [==============================] - 22s 45ms/step - loss: 6.2246 - accuracy: 0.0323\n",
      "Epoch 53/100\n",
      "484/484 [==============================] - 21s 44ms/step - loss: 6.1995 - accuracy: 0.0324\n",
      "Epoch 54/100\n",
      "484/484 [==============================] - 22s 44ms/step - loss: 6.1710 - accuracy: 0.0340\n",
      "Epoch 55/100\n",
      "484/484 [==============================] - 22s 45ms/step - loss: 6.1497 - accuracy: 0.0325\n",
      "Epoch 56/100\n",
      "484/484 [==============================] - 22s 45ms/step - loss: 6.1258 - accuracy: 0.0333\n",
      "Epoch 57/100\n",
      "484/484 [==============================] - 22s 45ms/step - loss: 6.1010 - accuracy: 0.0340\n",
      "Epoch 58/100\n",
      "484/484 [==============================] - 22s 45ms/step - loss: 6.0765 - accuracy: 0.0358\n",
      "Epoch 59/100\n",
      "484/484 [==============================] - 22s 45ms/step - loss: 6.0562 - accuracy: 0.0344\n",
      "Epoch 60/100\n",
      "484/484 [==============================] - 22s 45ms/step - loss: 6.0325 - accuracy: 0.0351\n",
      "Epoch 61/100\n",
      "484/484 [==============================] - 22s 45ms/step - loss: 6.0040 - accuracy: 0.0363\n",
      "Epoch 62/100\n",
      "484/484 [==============================] - 22s 46ms/step - loss: 5.9812 - accuracy: 0.0358\n",
      "Epoch 63/100\n",
      "484/484 [==============================] - 22s 46ms/step - loss: 5.9613 - accuracy: 0.0375\n",
      "Epoch 64/100\n",
      "484/484 [==============================] - 22s 46ms/step - loss: 5.9392 - accuracy: 0.0373\n",
      "Epoch 65/100\n",
      "484/484 [==============================] - 22s 46ms/step - loss: 5.9175 - accuracy: 0.0373\n",
      "Epoch 66/100\n",
      "484/484 [==============================] - 22s 46ms/step - loss: 5.8956 - accuracy: 0.0384\n",
      "Epoch 67/100\n",
      "484/484 [==============================] - 22s 46ms/step - loss: 5.8726 - accuracy: 0.0396\n",
      "Epoch 68/100\n",
      "484/484 [==============================] - 22s 46ms/step - loss: 5.8503 - accuracy: 0.0390\n",
      "Epoch 69/100\n",
      "484/484 [==============================] - 23s 48ms/step - loss: 5.8305 - accuracy: 0.0413\n",
      "Epoch 70/100\n",
      "484/484 [==============================] - 22s 46ms/step - loss: 5.8077 - accuracy: 0.0387\n",
      "Epoch 71/100\n",
      "484/484 [==============================] - 22s 46ms/step - loss: 5.7931 - accuracy: 0.0410\n",
      "Epoch 72/100\n",
      "484/484 [==============================] - 22s 45ms/step - loss: 5.7731 - accuracy: 0.0415\n",
      "Epoch 73/100\n",
      "484/484 [==============================] - 22s 45ms/step - loss: 5.7572 - accuracy: 0.0409\n",
      "Epoch 74/100\n",
      "484/484 [==============================] - 22s 46ms/step - loss: 5.7387 - accuracy: 0.0415\n",
      "Epoch 75/100\n",
      "484/484 [==============================] - 22s 46ms/step - loss: 5.7195 - accuracy: 0.0415\n",
      "Epoch 76/100\n",
      "484/484 [==============================] - 22s 46ms/step - loss: 5.7005 - accuracy: 0.0409\n",
      "Epoch 77/100\n",
      "484/484 [==============================] - 22s 45ms/step - loss: 5.6837 - accuracy: 0.0415\n",
      "Epoch 78/100\n",
      "484/484 [==============================] - 22s 45ms/step - loss: 5.6682 - accuracy: 0.0427\n",
      "Epoch 79/100\n",
      "484/484 [==============================] - 22s 45ms/step - loss: 5.6525 - accuracy: 0.0418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "484/484 [==============================] - 21s 43ms/step - loss: 5.6730 - accuracy: 0.0420\n",
      "Epoch 81/100\n",
      "484/484 [==============================] - 21s 43ms/step - loss: 5.6371 - accuracy: 0.0427\n",
      "Epoch 82/100\n",
      "484/484 [==============================] - 21s 43ms/step - loss: 5.6171 - accuracy: 0.0440\n",
      "Epoch 83/100\n",
      "484/484 [==============================] - 21s 43ms/step - loss: 5.5995 - accuracy: 0.0437\n",
      "Epoch 84/100\n",
      "484/484 [==============================] - 21s 43ms/step - loss: 5.5835 - accuracy: 0.0455\n",
      "Epoch 85/100\n",
      "484/484 [==============================] - 21s 44ms/step - loss: 5.5646 - accuracy: 0.0473\n",
      "Epoch 86/100\n",
      "484/484 [==============================] - 21s 44ms/step - loss: 5.5490 - accuracy: 0.0453\n",
      "Epoch 87/100\n",
      "484/484 [==============================] - 21s 44ms/step - loss: 5.5318 - accuracy: 0.0470\n",
      "Epoch 88/100\n",
      "484/484 [==============================] - 21s 44ms/step - loss: 5.5237 - accuracy: 0.0471\n",
      "Epoch 89/100\n",
      "484/484 [==============================] - 21s 44ms/step - loss: 5.5143 - accuracy: 0.0476\n",
      "Epoch 90/100\n",
      "328/484 [===================>..........] - ETA: 6s - loss: 5.4885 - accuracy: 0.0460"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f2/ntmdlj716y3_w74v5059sr2c0000gn/T/ipykernel_8410/3454637271.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/tf_certificate/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_certificate/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_certificate/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_certificate/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_certificate/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/tf_certificate/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf_certificate/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(predictors, label, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480db18a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "tf_certificate",
   "language": "python",
   "name": "tf_certificate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
